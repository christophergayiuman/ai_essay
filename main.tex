\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{biblatex}
\addbibresource{references.bib}
\bibliographystyle{}

\title{\textsc{Are We Ready For An AI-based Minority Report?}}
\author{Christopher Ga Yiu Man }
\date{\today}

%%% Some Packages
\usepackage{enumitem} %modifying lists


%Header information
\pagestyle{headings}

%%% Paragraph spacing and indents
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\usepackage{titlesec}
\titlespacing{\section}{0pt}{8pt}{0pt}
\titlespacing{\subsection}{0pt}{8pt}{0pt}

%%% Essay here
\begin{document}

\maketitle

\section{Introduction}

The movie “Minority Report” \cite{minority-report_2002} an action/sci-fi movie was released on July 21st 2002, and directed by Steven Spielberg. The movie dives into a world where technology is able to predict the future to the extent that the police are able to adapt technology and use Artificial Intelligence (AI),  in order to predict if a person is going to commit a criminal act before it has even happened. Due to the nature and subject of AI, many questions and problems both moral and ethical will have to be taken into account in order for a deep analysis of such technology. Hence in application of this technology into today's society, the question arises “Are We Ready For An AI-based Minority Report?”. Throughout this essay, an attempt will be made to explain and increase one’s understanding of the problem and provide a potential solution through a balanced even argument. 

\section{The Problem}
The first problem that arises with such powerful predictive technology is the question of who the creator is and of what purpose the predictive AI serves. An author of such technology will have to question his/her own moral and ethical decision making, and balance the fine line between the two. Ethics refers to a set of rules and pathways in which society helps construct in order to develop a well rounded individual that contributes to society as a whole in a positive manner \cite{merriam-webster}. Whereas morality is developed from a sense of personal principles that one follows through his or her life, a sense of what's innately good and bad \cite{cambridge-dictionary}. 

A problem with having a single person or small minority of people developing a predictive artificial intelligence based on ethical decision making, is that ethics change over time depending on societal norms and patterns at any given juncture. An example of this is through the journey of modern day medical ethics. A paper by K C Calman \cite{calman_2004} illustrates the fact that over a span of a decade or more what was once deemed as an ethical practice is now highly controversial and looked down upon. Hence, any AI that is developed in the current time based upon today’s ethical decision making, could be deemed as barbaric and dangerous to the larger population by future researchers and generations.  

If there were to be critiques about the artificial intelligence technology, a problem arises as to how such critiques and feedback is received and interpreted by the authors of such technology.  The famous whistleblower, Edward Snowdon, is a prime example of how one’s regard for technology being used in an unethical manner resulting in him putting his own life at risk.  Snowdon felt the only way he could critique and bring public awareness to his perceived unethical use of such powerful technology in the US, was by releasing and leaking details of the technology and its use to the general public. He was charged with "willful communication of classified communications intelligence information to an unauthorized person." \cite{biography.com_2019} Snowden was exiled into Russia for him to live the rest of his life. If such a strong reaction is applied to the predictive AI technology in the ‘Minority Report’ film, one could assume that the authors of such technology also garner significant power and control, and are also likely to disregard any critique or comments.  The person or group of people in charge of the creation and maintenance of this AI have an astronomical amount of responsibility.  As such, they must take into consideration the impact that such technology can have on society. On one hand, if the authors are according to society very ethical, this technology can be proven to be very useful in helping society in a very positive manner.  However, taking the worst case scenario, and the technology is used irresponsibly without appropriate ethical standards, the negative impact on our environment and society as a whole can have irreversible damage. Therefore, the positive and negative use of such technology must be weighed properly and managed carefully.

If the authors of such predictive AI technologies invent such technologies based upon moral factors there are also other implications that can be presented. “Good people can do bad things'' \cite{ellemers_toorn_paunov} eloquently and simply illustrates how one's perspective changes the positivity of an outcome. If this predictive technology had predicted that a person was going to commit a crime but was stopped by the police before it could be committed could have a negative butterfly effect. A butterfly effect is the understanding that a small action could have large and irreversible changes occur as explained by Jamie L. Vernon on the American Scientist \cite{vernon_2017}. A possible outcome of this AI is that a group of people split by race, ethnicity or gender could have a higher chance of being imprisoned by such technology. Using current day statistics provided by the US Department of Justice \cite{carson_2020} indicates that 93 percent of the total prison population at the end of 2018 was male. If this predictive AI technology was to imprison a large portion of the male population in prisons or jails this could have a butterfly effect that could largely hinder the population as a whole. For example, it could remove the large population of males in the workforce. In Canada only 12.1 percent of women work in construction and 21.6 percent of females in Manufacturing/Durables \cite{catalyst_2020}. This shows that if the predictive AI was to imprison males based on statistical data, we would have large industries that would be destroyed due to the lack of workers. This then could go on to impact the world's economy as a whole.

\section{The Solution}

If this technology was to be implemented and to operate in the most effective positive manner, two main factors would have to be put in place and maintained so that the AI technology could be managed by a large group of people and have the ability to be turned off at any given time.

The first solution would be to have the AI be controlled and receive data by the mass population of human beings, or by human beings that are affected by the AI technology. The solution would have the AI technology use data and input by each human individually impacted by the AI and operate as a hive mind, similar to how bee’s operate. “The entire colony, consisting of tens thousands of individuals, works like a single human nervous system, with each bee behaving like a neuron. When they make a decision, such as choosing where to build a nest, individual bees opt for different choices and they support and veto each other until they reach a consensus.” \cite{yong_2019} This “hive mind” way of operating would solve the problem of both having ethical and moral factors taken into account. It would also solve the issue of having a small group or single person managing in the creation of such AI as its neural network would be developed from the larger human population. Hence, the actions and data trends of the AI network are directly impacted by each individual but also by the whole of society at the same time.

The solution of the Hive mind only relates to the purpose of data input and how the AI is controlled. The solution does not interfere with the outcome of the artificial intelligence minority report. Rather the solution proposed is a way that the system could work with a level of shared responsibility and input. The solution being a hive mind neural network of input intends to use the AI to propel humanity forward in evolution.  However, there are two possible perspectives that should be taken into account, firstly, do we need a system like this in place at all or, is there a better system that could be developed?

\subsection{Argument For}
The hive mind method of AI data input/development would mean that each individual’s data (however that may be processed by the AI) acts as if there is a moral factor, but when combined with the larger trend of the human population, it will become the ethical standards in which the AI operates. As the moral standards of individuals change over time, the AI should dynamically adjust its ethical standards based upon the current data’s moral factors and input from the human data. Hence the blend of both ethical and moral decision making would be taken into account when the predictive AI is doing calculations whilst being dynamically updated whenever common ethical trends change over time. This would suggest that the solution to such technology would have a positive outcome regardless of time period or when it was developed, as it is dynamically updating and changing depending on the current societal norms and ethical beliefs at any given moment in time. Another positive outcome of having the solutions work as well as having the technology function as it should, would be that the future generations would be less likely to commit crimes hence create a better and safer society. 

If the aforementioned solutions using AI worked positively over the longer term, such positive impacts on the global scale could include worldwide peace. “In 2019 the United States spent around 718.69 billion U.S. dollars on its military.” \cite{duffin_2020} Due to the expensive nature of war and the military, if worldwide peace could be achieved due to the Predictive AI, and the nature of it lowering crime rates, we could see different sectors of our economy flourish and improve dramatically if such funding is diverted to other areas of society such as art, technology, and inter space exploration. 

“The cost of the International Space Station, including development, assembly and running costs over 10 years, comes to €100 billion. High technology on the space frontier is not cheap.” \cite{the-european-space-agency} In one year of the United states maintaining and building the military, the human race could build and maintain roughly 7 to 8 new International Space stations (ISS). The increase of a space workforce would help push technology and science further then it could have been before due to new technologies being developed for the new ISS’s as well as the further understandings of how space and space exploration operates.

We could see huge improvements in the medical sciences industry if the money previously spent on the military and to fund wars was put into medical research. “The total amount that the United States spent on medical and health R&D in 2016 reached 171.8 Billion” According to Research America \cite{research-america_2017} If the money alone spent on the US military in one year was put into medical research in the USA, the positive impact on this could help to develop and sustain international universal healthcare in less developed countries worldwide, on top of enabling further research and development to solve global medical mysteries such as the causes of cancer, old age and protein folding. 

 From a positive outcome perspective, it is clear that there would be a significant positive impact globally in terms of economical, medical, and scientific progress through the utilisation of predictive AI technology.  However, this assumption is made on the basis that the redistribution of money not spent on the military and funding wars, would be smartly handled and used in ways that would both help benefit each country worldwide.

\subsection{Argument Against}

One negative impact of the technology that includes the suggested solution to many of the problems that AI technology presents, arises when the users of the AI technology are unwilling to participate in such a programme. A dissertation written by Ashly Adam Townsen in 2015 \cite{townsen_2015} encapsulates the fact that a person's personality is consistent and is represented by their expected behaviour. This represents the fact that if a person does not want to partake or has views that differ from the predictive AI, it will be deemed difficult to persuade such an individual or group of people to be accepting of the outcome that the AI can predict. Furthermore, such unwillingness to participate in the AI programme, could increase conflict around the world as those unwilling to participate could clash with those in authority or other pro-users of the AI programme. This possible outcome is counteractive to the purpose of the AI which would lower crime rate and arrest people before they commit crimes as the AI itself would indirectly be the catalyst for individuals to be in conflict and commit crimes. Another point of conflict that could arise, is that religious individuals could regard participating in this AI technology to be  seen as ‘unfaithful’ to their religion by allowing this technology to in a sense “read their future” and dictate their actions, which may be directly opposing their beliefs on ‘god’ and their own religious systems. In effect, this AI “solution” could actually be deemed to cause more conflict then it resolves, which is its main purpose. 

Another foreseeable outcome of this AI is that people that are imprisoned before they have committed a crime and are locked away or shunned by society will be split into their own category. “In 2013/14, there were 47,571 ‘racist incidents’ recorded by the police in England and Wales. On average, that is about 130 incidents per day.” \cite{institute-of-race-relations} Due to the large amount of racism that already occurs in today's world we could see this being amplified by the AI grouping people into different categories based on something they haven't even done yet. The large divide that is created between the already divided people of today's society would easily deem to cause mass conflicts between the two groups of people, people that have not committed any act of criminal offense and a group that is likely to cause an act of violence/criminal act.  In this case, the predictive AI could unintentionally make the world a more dangerous place with more divided societies that could spur war and conflicts both internally in countries, as well as globally.  Division could be further seen in society by those “non-criminals” and “potential-criminals” as determined by the artificial intelligence.

The causes of potential criminal acts could be further skewed and amplified by the judicial system in which the AI responds to.  For example, judicial systems vary dramatically around the world including the way in which judicial sentences and prosecutions are applied.  Some countries may adopt a more lenient approach, whereas other countries may have a very strict regime and be less tolerant for criminal acts or perceived acts against humanity or society. The use of this predictive AI could be somewhat problematic as decision making will be very ‘black and white’ based on predictive outcome without any human consciousness or understanding of human behavior.  This could lead to the predictive AI making decision that could be deemed  fundamentally unethical and ‘unhuman-like’.   

Another possible negative outcome of this AI and the solution implemented is that if there was a decrease in war and conflicts, society as a whole would see a decline in the production and inspiration in the arts. “There was a kind of aestheticization of trauma,” \cite{johnson_2012} The Los Angeles Times article “Art Forever Changed by World War 1” represented how the first world war had sparked inspiration for hundreds of different artists around the world. Their art amplified the emotions of the people at the time. However, without any war or conflict due to the AI arresting and detaining people that commit crimes of any type, it could be predicted that over a long span of time, common literature and art would decline as there would be less inspiration to express their trauma through forms of art.

Another issue with the decline in war and conflicts is that there could possibly be a direct decline in technological development. In WW2 there were large technological advancements that resulted from the war such as the production and invention of small firearms, different types of aircrafts etc. \cite{armed-forces-museum_2019} The main reason for the large technological development is that through technology, humans are able to perfect the art of war through many different avenues and techniques. The decrease in military research and development will directly impact civilian technology access. This can be perceived as a negative, due to the fact that technology tends to assist human beings over time when there is a deemed need, such as improved weaponry, aircraft and transportation systems during times of war or conflict. As such, a large decline in technological advancement could be seen as a type of societal regression in the modern day. This is however, again based upon perspective, as this is looking at the technological advancement in relation to human evolution. The perspective of a decreased war could be viewed very positively from another angle.  It can be seen through the scenarios outlined, that during times of conflict and wars there is a corresponding historical trend in technological advancement, that propels humanity forward in terms of research and development. By eliminating the need for such technological advancement could have a detrimental effect on human evolution resulting in a direct impact on the future of human civilization and history itself. 
\section{Conclusion}
To answer the question “Are We Ready For An AI-based Minority Report?” we would need to consider and clearly identify the purpose and objective of such a programme, and to consider any other alternative programmes or solutions. By evaluating the pros and cons of this predictive AI, taking into account the ethical and moral factors, as well as the provided solutions of the hive mind, the predictive AI is still not able to take into consideration the ‘randomness’ of human nature and behaviour. Given that the very nature of humans and their behaviour is unique and unpredictable, it is likely to be ineffective to implement a system that is “black and white” such as the predictive artificial intelligence technology. Technology based on human behaviour is also to some extent unreliable as the data received and analysed is constructed from a degree of randomness that human behaviour presents. Henceforth, it appears that as a society and human race, we are not yet ready to adopt this specific type of AI based minority report



\section*{Bibliography}
\printbibliography


%\begin{enumerate}[noitemsep]
    %\item Ager, David W. 2018. Some Article. \textit{Journal of special magic}. 23(3): 14-17.
    %\item Ager, David W. 2018. Some Article. \textit{Journal of special magic}. 23(3): 14-17.
%\end{enumerate}


\end{document}
